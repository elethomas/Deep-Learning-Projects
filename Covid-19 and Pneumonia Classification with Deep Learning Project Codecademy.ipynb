{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3208d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import app\n",
    "\n",
    "###1) Data is split into train and test\n",
    "#   X-ray scans are in grayscale\n",
    "#   Three classes (Covid, Normal, Pneumonia), so this is a multi-class classification problem\n",
    "\n",
    "###2) Initialise ImageDataGenerator object\n",
    "data_generator = ImageDataGenerator(rescale = 1.0/255)\n",
    "# print its attributes:\n",
    "print(data_generator.__dict__)\n",
    "\n",
    "###3) Loading the data (iterators)\n",
    "# set batch size \n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# training iterator \n",
    "training_iterator = data_generator.flow_from_directory('augmented-data/test', class_mode = 'categorical', color_mode = 'grayscale', batch_size = BATCH_SIZE)\n",
    "\n",
    "# validation iterator\n",
    "validation_iterator = data_generator.flow_from_directory('augmented-data/train', class_mode = 'categorical', color_mode = 'grayscale', batch_size = BATCH_SIZE)\n",
    "\n",
    "# sample batch of data and print its dimensions\n",
    "sample_batch_input,sample_batch_labels = training_iterator.next()\n",
    "print(sample_batch_input.shape,sample_batch_labels.shape)\n",
    "\n",
    "###4) Create classification model\n",
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "# input shape\n",
    "model.add(layers.Input(shape = (256, 256, 1)))\n",
    "# first convolutional layer, 8 filters each 3x3 with strides of 2\n",
    "model.add(tf.keras.layers.Conv2D(8, 3, strides = 2, activation='relu')) \n",
    "# pooling\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "# second convolutional layer, 8 filters each 3x3 with strides of 2\n",
    "model.add(tf.keras.layers.Conv2D(8, 3, strides = 2, activation='relu')) \n",
    "# pooling\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "# flatten layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# hidden dense layer with 16 units\n",
    "model.add(tf.keras.layers.Dense(16, activation = 'relu'))\n",
    "# output dense layer, three classes\n",
    "model.add(tf.keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = tf.keras.losses.CategoricalCrossentropy(), metrics = [tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()])\n",
    "\n",
    "###5) Fit and evaluate model\n",
    "# fit model\n",
    "history = model.fit(training_iterator, steps_per_epoch = training_iterator.samples/BATCH_SIZE,\n",
    "epochs = 5, validation_data = validation_iterator, validation_steps = validation_iterator.samples/BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Matplotlib extension below\n",
    "# plotting categorical and validation accuracy over epochs\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax1.plot(history.history['categorical_accuracy'])\n",
    "ax1.plot(history.history['val_categorical_accuracy'])\n",
    "ax1.set_title('model accuracy')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# plotting auc and validation auc over epochs\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "ax2.plot(history.history['auc'])\n",
    "ax2.plot(history.history['val_auc'])\n",
    "ax2.set_title('model auc')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('auc')\n",
    "ax2.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# used to keep plots from overlapping\n",
    "fig.tight_layout()\n",
    "\n",
    "# use this savefig call at the end of your graph instead of using plt.show()\n",
    "fig.savefig('static/images/my_plots.png')\n",
    "\n",
    "\n",
    "###Implementing a Classification Report and a Confusion Matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "test_steps_per_epoch = np.math.ceil(validation_iterator.samples / validation_iterator.batch_size)\n",
    "predictions = model.predict(validation_iterator, steps = test_steps_per_epoch)\n",
    "predicted_classes = np.argmax(predictions, axis = 1)\n",
    "true_classes = validation_iterator.classes\n",
    "class_labels = list(validation_iterator.class_indices.keys())\n",
    "report = classification_report(true_classes, predicted_classes, target_names = class_labels)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

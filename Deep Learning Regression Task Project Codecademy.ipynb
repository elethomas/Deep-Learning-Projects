{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44322fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#My Answer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow\timport keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "data = pd.read_csv('Admission_Predict.csv')\n",
    "#print(data.head())\n",
    "#print(data.columns)\n",
    "#print(data.describe())\n",
    "#print(data.dtypes)\n",
    "\n",
    "#Drop serial number column (no use for predicting admission success)\n",
    "data = data.drop(['Serial No.'], axis = 1)\n",
    "#print(data.columns)\n",
    "\n",
    "#Split dataset into labels and features\n",
    "labels = data.iloc[:, -1]\n",
    "features = data.iloc[:, 0:-1]\n",
    "\n",
    "#Split data into training and test\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Normalise the numeric columns using ColumnTransformer\n",
    "ct = ColumnTransformer([('norm', Normalizer(), features.columns)], remainder='passthrough')\n",
    "\n",
    "#Fit the normalizer to the training and test data \n",
    "features_train_norm = ct.fit_transform(features_train) \n",
    "features_test_norm = ct.transform(features_test) \n",
    "\n",
    "#Convert from numpy arrays to pandas frame\n",
    "features_train_norm = pd.DataFrame(features_train_norm, columns = features_train.columns)\n",
    "features_test_norm = pd.DataFrame(features_test_norm, columns = features_test.columns)\n",
    "\n",
    "####Create neural network to perform a regression analysis on the admission data####\n",
    "model = Sequential()\n",
    "input = layers.InputLayer(input_shape = (features.shape[1], ))\n",
    "\n",
    "#Add input layer to the model\n",
    "model.add(input)\n",
    "\n",
    "#Add one hidden layer with 64 hidden units, using relu activation functions\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "\n",
    "#Add an output layer with one neuron\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = optimizers.Adam(learning_rate = 0.01)\n",
    "model.compile(loss = 'mse', metrics = ['mae'], optimizer = opt)\n",
    "\n",
    "\n",
    "####Hyperparameter tuning####\n",
    "num_epochs = 80\n",
    "batch_size = 5\n",
    "\n",
    "#Initialise early stopping\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(features_train_norm, labels_train, epochs = num_epochs, batch_size = batch_size, verbose=1, validation_split = 0.2, callbacks = [es])\n",
    "\n",
    "\n",
    "#Evaluate training model on preprocessed test dataset\n",
    "res_mse, res_mae = model.evaluate(features_test_norm, labels_test, verbose = 0)\n",
    "# print validation mean squared error and mean absolute error\n",
    "print('MSE: ', res_mse)\n",
    "print('MAE: ', res_mae)\n",
    "\n",
    "# evaluate R-squared score\n",
    "y_pred = model.predict(features_test_norm)\n",
    "print('R^2: ', r2_score(labels_test, y_pred))\n",
    "\n",
    "# Do extensions code below\n",
    "# if you decide to do the Matplotlib extension, you must save your plot in the directory by uncommenting the line of code below\n",
    "\n",
    "# fig.savefig('static/images/my_plots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Same code as above, but using design_model function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow\timport keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "data = pd.read_csv('Admission_Predict.csv')\n",
    "#print(data.head())\n",
    "#print(data.columns)\n",
    "#print(data.describe())\n",
    "#print(data.dtypes)\n",
    "\n",
    "#Drop serial number column (no use for predicting admission success)\n",
    "data = data.drop(['Serial No.'], axis = 1)\n",
    "#print(data.columns)\n",
    "\n",
    "#Split dataset into labels and features\n",
    "labels = data.iloc[:, -1]\n",
    "features = data.iloc[:, 0:-1]\n",
    "\n",
    "#Split data into training and test\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Normalise the numeric columns using ColumnTransformer\n",
    "ct = ColumnTransformer([('norm', Normalizer(), features.columns)], remainder='passthrough')\n",
    "\n",
    "#Fit the normalizer to the training and test data \n",
    "features_train_norm = ct.fit_transform(features_train) \n",
    "features_test_norm = ct.transform(features_test) \n",
    "\n",
    "#Convert from numpy arrays to pandas frame\n",
    "features_train_norm = pd.DataFrame(features_train_norm, columns = features_train.columns)\n",
    "features_test_norm = pd.DataFrame(features_test_norm, columns = features_test.columns)\n",
    "\n",
    "\n",
    "# design deep learning model\n",
    "def design_model(features, learning_rate):\n",
    "    # initialize Sequential model\n",
    "    model = Sequential()\n",
    "    # create the input layer\n",
    "    input = layers.InputLayer(input_shape=(features.shape[1],))\n",
    "    # add the input layer to the model\n",
    "    model.add(input)\n",
    "    # add 2 hidden layers\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    # add an output layer to the model\n",
    "    model.add(layers.Dense(1))\n",
    "    # initialize an Adam optimizer\n",
    "    opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "    # compile model\n",
    "    model.compile(loss='mse', metrics=['mae'], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.05\n",
    "epochs = 100\n",
    "batch_size = 5\n",
    "\n",
    "model = design_model(features_train_norm, learning_rate)\n",
    "print(model.summary())\n",
    "\n",
    "# initialize EarlyStopping that monitors the validation loss\n",
    "stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(features_train_norm, labels_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2, callbacks=[stop])\n",
    "# evaluate the model on the test data\n",
    "val_mse, val_mae = model.evaluate(features_test_norm, labels_test, verbose=0)\n",
    "\n",
    "# print validation mean squared error and mean absolute error\n",
    "print('MSE: ', val_mse)\n",
    "print('MAE: ', val_mae)\n",
    "\n",
    "# evaluate R-squared score\n",
    "y_pred = model.predict(features_test_norm)\n",
    "print('R^2: ', r2_score(labels_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda388ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Same code as above, but using design_model function and fit_model function **** NEED TO COMPLETE\n",
    "def fit_model(f_train, l_train, learning_rate, num_epochs):\n",
    "    #build the model: to see the specs go to model.pyl we increased the number of hidden neurons\n",
    "    #in order to introduce some overfitting\n",
    "    model = design_model(features_train, learning_rate) \n",
    "    #train the model on the training data\n",
    "    es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n",
    "    history = model.fit(features_train, labels_train, epochs=num_epochs, batch_size= 16, verbose=0, validation_split = 0.2, callbacks = [es])\n",
    "    return history\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_epochs = 500\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n",
    "history = model.fit(features_train, labels_train, epochs=num_epochs, batch_size= 16, verbose=0, validation_split = 0.2, callbacks = [es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333f697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78dfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**** LOOK INTO USING GRID SEARCH OR RANDOMISED SEARCH FOR HYPERPARAMETER TUNING\n",
    "\n",
    "#https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "#https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_grid_search():\n",
    "  batch_size = [6, 64]\n",
    "  epochs = [10, 50]\n",
    "  learning_rate = [0.1, 0.01, 0.001]\n",
    "  model = KerasRegressor()\n",
    "  param_grid = dict(batch_size=batch_size, epochs=epochs, learning_rate = learning_rate)\n",
    "  grid = GridSearchCV(estimator = model, param_grid=param_grid, scoring = make_scorer(mean_squared_error, greater_is_better=False),return_train_score = True)\n",
    "  grid_result = grid.fit(features_train, labels_train, verbose = 0)\n",
    "  print(grid_result)\n",
    "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "  means = grid_result.cv_results_['mean_test_score']\n",
    "  stds = grid_result.cv_results_['std_test_score']\n",
    "  params = grid_result.cv_results_['params']\n",
    "  for mean, stdev, param in zip(means, stds, params):\n",
    "      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "  print(\"Training\")\n",
    "  means = grid_result.cv_results_['mean_train_score']\n",
    "  stds = grid_result.cv_results_['std_train_score']\n",
    "  for mean, stdev, param in zip(means, stds, params):\n",
    "      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "print(\"-------------- GRID SEARCH --------------------\")\n",
    "do_grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95233584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c562d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "###BELOW ARE ACTUAL ANSWERS FROM GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual Answer from Github\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# import dataset as pandas DataFrame\n",
    "admissions = pd.read_csv('admissions_data.csv')\n",
    "\n",
    "# inspect the columns and data types \n",
    "print(admissions.columns)\n",
    "print(admissions.head())\n",
    "print(admissions.describe())\n",
    "\n",
    "# all variables are numerical\n",
    "\n",
    "# split data into feature parameters and labels\n",
    "\n",
    "# except for the first and last column, all in between columns are set as our feature parameters\n",
    "features = admissions.iloc[:, 1:-1]\n",
    "# last column is the feature we want to predict and contains the labels we'll use\n",
    "labels = admissions.iloc[:, -1]\n",
    "\n",
    "# split data into training and test sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=5)\n",
    "\n",
    "# scale features\n",
    "\n",
    "# initialize scaling object\n",
    "ct = ColumnTransformer([('scale', StandardScaler(), features.columns)])\n",
    "\n",
    "# fit ColumnTransformer to the training data and transform it\n",
    "features_train_scaled = ct.fit_transform(features_train)\n",
    "# transform test data using the trained ColumnTransformer\n",
    "features_test_scaled = ct.transform(features_test)\n",
    "\n",
    "# design deep learning model\n",
    "def design_model(features, learning_rate):\n",
    "    # initialize Sequential model\n",
    "    model = Sequential()\n",
    "    # create the input layer\n",
    "    input = layers.InputLayer(input_shape=(features.shape[1],))\n",
    "    # add the input layer to the model\n",
    "    model.add(input)\n",
    "    # add 3 hidden layers and 3 dropout layers\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    # add an output layer to the model\n",
    "    model.add(layers.Dense(1))\n",
    "    # initialize an Adam optimizer\n",
    "    opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "    # compile model\n",
    "    model.compile(loss='mse', metrics=['mae'], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 80\n",
    "batch_size = 1\n",
    "\n",
    "model = design_model(features_train_scaled, learning_rate)\n",
    "print(model.summary())\n",
    "\n",
    "# initialize EarlyStopping that monitors the validation loss\n",
    "stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(features_train_scaled, labels_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2, callbacks=[stop])\n",
    "# evaluate the model on the test data\n",
    "val_mse, val_mae = model.evaluate(features_test_scaled, labels_test, verbose=0)\n",
    "\n",
    "# print validation mean squared error and mean absolute error\n",
    "print('MSE: ', val_mse)\n",
    "print('MAE: ', val_mae)\n",
    "\n",
    "# evaluate R-squared score\n",
    "y_predicted = model.predict(features_test_scaled)\n",
    "print('R^2: ', r2_score(labels_test,y_predicted))\n",
    "\n",
    "\n",
    "# plot learning curves\n",
    "\n",
    "# loss vs epochs\n",
    "fig, axs = plt.subplots(1, 2, gridspec_kw={'hspace': 1, 'wspace': 0.5}) \n",
    "(ax1, ax2) = axs\n",
    "ax1.plot(history.history['loss'], label='train')\n",
    "ax1.plot(history.history['val_loss'], label='validation')\n",
    "ax1.set_title('lrate=' + str(learning_rate))\n",
    "ax1.legend(loc=\"upper right\")\n",
    "ax1.set_xlabel(\"# of epochs\")\n",
    "ax1.set_ylabel(\"loss (mse)\")\n",
    "\n",
    "# mae vs epochs\n",
    "ax2.plot(history.history['mae'], label='train')\n",
    "ax2.plot(history.history['val_mae'], label='validation')\n",
    "ax2.set_title('lrate=' + str(learning_rate))\n",
    "ax2.legend(loc=\"upper right\")\n",
    "ax2.set_xlabel(\"# of epochs\")\n",
    "ax2.set_ylabel(\"MAE\")\n",
    "\n",
    "\n",
    "plt.savefig('my_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da00f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another answer from Github\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow\timport keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "df = pd.read_csv('admissions_data.csv')\n",
    "#print(df.head())\n",
    "#print(df.columns)\n",
    "#print(df.describe())\n",
    "#print(df.dtypes)\n",
    "\n",
    "labels = df.iloc[:, -1]\n",
    "#print(labels)\n",
    "features = df.iloc[:, 0:-1]\n",
    "#print(features)\n",
    "#print(df['University Rating'])\n",
    "features.drop(['University Rating', 'Serial No.'], axis=1, inplace=True)\n",
    "#print(features.columns)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_train_scaled = scaler.fit_transform(features_train)\n",
    "features_test_scaled = scaler.transform(features_test)\n",
    "\n",
    "model = Sequential()\n",
    "input = layers.InputLayer(input_shape=(features.shape[1],))\n",
    "model.add(input)\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "opt = Adam(learning_rate=0.05)\n",
    "model.compile(loss='mse', metrics=['mae'], optimizer=opt)\n",
    "\n",
    "stop=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=40)\n",
    "\n",
    "\n",
    "history = model.fit(features_train_scaled, labels_train, epochs=500, batch_size=30, verbose=1, validation_split=0.2, callbacks=[stop])\n",
    "\n",
    "res_mse, res_mae = model.evaluate(features_test_scaled, labels_test)\n",
    "print(res_mse, res_mae)\n",
    "\n",
    "y_pred = model.predict(features_test_scaled)\n",
    "print('R^2: ', r2_score(labels_test, y_pred))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax1.plot(history.history['mae'])\n",
    "ax1.plot(history.history['val_mae'])\n",
    "ax1.set_title('model mae')\n",
    "ax1.set_ylabel('MAE')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_title('model loss')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'validation'], loc='upper left')\n",
    " \n",
    "fig.tight_layout()\n",
    "fig.savefig('static/images/my_plots.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
